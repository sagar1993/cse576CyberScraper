{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Combine all data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "\n",
    "path = '../data/'\n",
    "files = listdir('../data/')\n",
    "df = pd.DataFrame(columns=[\"url\", \"query\", \"text\"])\n",
    "\n",
    "for f in files:\n",
    "    temp = pd.read_csv(path + f)\n",
    "    if 'article-name' in temp.columns:\n",
    "        temp.rename(columns={'article-name':'name','article-url':'url','content':'text','keyword':'query'}, inplace=True)\n",
    "    if len(temp) < 1:\n",
    "        continue\n",
    "    df = df.append(temp)\n",
    "df.drop(['Unnamed: 0', 'name'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - data preprocessing\n",
    "    1. stop word removal\n",
    "    2. lower case letters\n",
    "    3. non ascii character removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def normalize_text(text):\n",
    "    norm_text = text.lower()\n",
    "    # Replace breaks with spaces\n",
    "    norm_text = norm_text.replace('<br />', ' ')\n",
    "    # Pad punctuation with spaces on both sides\n",
    "    norm_text = re.sub(r\"([\\.\\\",\\(\\)!\\?;:])\", \" \\\\1 \", norm_text)\n",
    "    return norm_text\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    return \" \".join([item.lower() for item in text.split() if item not in stop])\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    return ''.join([\"\" if ord(i) < 32 or ord(i) > 126 else i for i in text])\n",
    "\n",
    "df['text'] = df['text'].apply(remove_non_ascii)\n",
    "df['text'] = df['text'].apply(normalize_text)\n",
    "df['text'] = df['text'].apply(remove_stop_words)\n",
    "df[\"text\"] = df['text'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - a simple word2vec model\n",
    "    In this section we apply simple word to vec model to tokenized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_text'] = df.apply(lambda row: word_tokenize(row['text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(df['tokenized_text'], size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words for apt1\n",
      "('iranian', 0.999222993850708)\n",
      "('mandiant', 0.9991157054901123)\n",
      "('north', 0.9987305402755737)\n",
      "('according', 0.9986847639083862)\n",
      "('apt10', 0.997677206993103)\n",
      "('previously', 0.997546374797821)\n",
      "('launched', 0.9974732398986816)\n",
      "('discovered', 0.9972922801971436)\n",
      "('suspected', 0.9971252083778381)\n",
      "('related', 0.9971103668212891)\n",
      "\n",
      "\n",
      "Most similar words for apt3\n",
      "('team', 0.9952455759048462)\n",
      "('observed', 0.9951759576797485)\n",
      "('cyberespionage', 0.9946916103363037)\n",
      "('strontium', 0.9946668148040771)\n",
      "('spotted', 0.994046151638031)\n",
      "('cozy', 0.9936408996582031)\n",
      "('also', 0.993202269077301)\n",
      "('tracked', 0.9931139945983887)\n",
      "('aimed', 0.9927853345870972)\n",
      "('behind', 0.9927506446838379)\n",
      "\n",
      "\n",
      "Most similar words for apt10\n",
      "('apt37', 0.9993234276771545)\n",
      "('tracks', 0.999140739440918)\n",
      "('iranian', 0.9987781047821045)\n",
      "('overlap', 0.9986939430236816)\n",
      "('previously', 0.9986189007759094)\n",
      "('recently', 0.9984301328659058)\n",
      "('primarily', 0.9983476400375366)\n",
      "('statesponsored', 0.9979463815689087)\n",
      "('chinesespeaking', 0.9977914690971375)\n",
      "('associated', 0.997783899307251)\n",
      "\n",
      "\n",
      "Most similar words for apt17\n",
      "('apt32', 0.9991629123687744)\n",
      "('responsible', 0.9984322786331177)\n",
      "('oceanlotus', 0.9983528852462769)\n",
      "('variety', 0.9982239007949829)\n",
      "('hellsing', 0.998184859752655)\n",
      "('found', 0.998030424118042)\n",
      "('direct', 0.9979234933853149)\n",
      "('dukes', 0.9978929758071899)\n",
      "('suggesting', 0.9978482723236084)\n",
      "('actively', 0.9977899789810181)\n",
      "\n",
      "\n",
      "Most similar words for apt28\n",
      "('sofacy', 0.998396635055542)\n",
      "('storm', 0.998350977897644)\n",
      "('apt', 0.9977822303771973)\n",
      "('bear', 0.9975793361663818)\n",
      "('actor', 0.9974491000175476)\n",
      "('known', 0.9973563551902771)\n",
      "('pawn', 0.9969891309738159)\n",
      "('fancy', 0.9961714744567871)\n",
      "('platinum', 0.9952526688575745)\n",
      "('persistent', 0.9948386549949646)\n",
      "\n",
      "\n",
      "Most similar words for apt29\n",
      "('buckeye', 0.9962183833122253)\n",
      "('2010', 0.9956392049789429)\n",
      "('identified', 0.9951856136322021)\n",
      "('overlap', 0.99510657787323)\n",
      "('recent', 0.9950370192527771)\n",
      "('including', 0.9949251413345337)\n",
      "('overview', 0.9948657155036926)\n",
      "('axiom', 0.9946104288101196)\n",
      "('referred', 0.9945827722549438)\n",
      "('observed', 0.9943770170211792)\n",
      "\n",
      "\n",
      "Most similar words for apt30\n",
      "('ways', 0.9988441467285156)\n",
      "('like', 0.9988266229629517)\n",
      "('indicate', 0.9986801743507385)\n",
      "('apts', 0.9986655116081238)\n",
      "('shared', 0.9986509084701538)\n",
      "('looking', 0.9986438155174255)\n",
      "('heavily', 0.9986283183097839)\n",
      "('relatively', 0.9985643625259399)\n",
      "('breached', 0.9984544515609741)\n",
      "('interestingly', 0.9983111619949341)\n",
      "\n",
      "\n",
      "Most similar words for apt32\n",
      "('apt17', 0.9991629123687744)\n",
      "('found', 0.9988903999328613)\n",
      "('apt34', 0.9988247156143188)\n",
      "('tied', 0.9988231658935547)\n",
      "('detailed', 0.9987410306930542)\n",
      "('variety', 0.9986026883125305)\n",
      "('considered', 0.998522937297821)\n",
      "('shared', 0.9983890056610107)\n",
      "('mainly', 0.998370885848999)\n",
      "('looking', 0.9983633756637573)\n",
      "\n",
      "\n",
      "Most similar words for apt33\n",
      "('turla', 0.9991586208343506)\n",
      "('entities', 0.9991531372070312)\n",
      "('multiple', 0.9991229772567749)\n",
      "('countries', 0.9991114139556885)\n",
      "('operating', 0.9989201426506042)\n",
      "('determined', 0.9989131689071655)\n",
      "('noticed', 0.9989059567451477)\n",
      "('primarily', 0.9988879561424255)\n",
      "('naikon', 0.9987640380859375)\n",
      "('netherlands', 0.9987532496452332)\n",
      "\n",
      "\n",
      "Most similar words for apt34\n",
      "('aware', 0.9993754029273987)\n",
      "('destructive', 0.9993650913238525)\n",
      "('tied', 0.9993546009063721)\n",
      "('considered', 0.9988598823547363)\n",
      "('interests', 0.9988378882408142)\n",
      "('apt32', 0.9988248348236084)\n",
      "('ministries', 0.9988212585449219)\n",
      "('gothic', 0.9987506866455078)\n",
      "('confident', 0.9986671209335327)\n",
      "('gain', 0.9985947608947754)\n",
      "\n",
      "\n",
      "Most similar words for apt37\n",
      "('apt10', 0.9993234276771545)\n",
      "('tracks', 0.9988443851470947)\n",
      "('primarily', 0.9985034465789795)\n",
      "('recently', 0.9984588623046875)\n",
      "('associated', 0.9983247518539429)\n",
      "('identified', 0.9982351064682007)\n",
      "('chinesespeaking', 0.9980851411819458)\n",
      "('naikon', 0.9980514049530029)\n",
      "('turla', 0.998038113117218)\n",
      "('iranian', 0.9980124235153198)\n",
      "\n",
      "\n",
      "Most similar words for apt38\n",
      "('however', 0.9996230006217957)\n",
      "('early', 0.9992717504501343)\n",
      "('variety', 0.9992309212684631)\n",
      "('continues', 0.9990344047546387)\n",
      "('back', 0.9990178346633911)\n",
      "('region', 0.9989769458770752)\n",
      "('registered', 0.9989117383956909)\n",
      "('described', 0.9989078044891357)\n",
      "('hacker', 0.9988747835159302)\n",
      "('looking', 0.9988545775413513)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/born-2-code/.local/lib/python2.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "for num in [1, 3, 5, 10, 12, 16, 17, 18, 19, 28, 29, 30, 32, 33, 34, 37, 38]:\n",
    "    term = \"apt%s\"%str(num)\n",
    "    if term in model.wv.vocab:\n",
    "        print(\"Most similar words for %s\"%term)\n",
    "        for t in model.most_similar(term): print(t)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here we got one interesting result for apt17 as apt28\n",
    "    but for all other word2vec results we observe that we are getting names like malware, attackers, groups, backdoor in the most similar items.  \n",
    "    It might be the case that the names of attacker groups are ommited because they are phrases instead simple words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - word2vec with bigram phrases\n",
    "    here we try to find bigram phrases from the dataset and apply word2vec model to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Phrases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram.add_vocab(df['tokenized_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cyber_security       353\n",
      "security_conference  334\n",
      "ics_cyber            334\n",
      "document_getelementsbytagname 163\n",
      "comjsplusone_js      163\n",
      "conference_singapore 163\n",
      "google_comjsplusone  163\n",
      "script_0             163\n",
      "ciso_forum           163\n",
      "forum_half           163\n",
      "document_createelement 163\n",
      "po_src               163\n",
      "apis_google          163\n",
      "textjavascript_po    163\n",
      "type_textjavascript  163\n",
      "po_async             163\n",
      "var_po               163\n",
      "parentnode_insertbefore 163\n",
      "async_true           163\n",
      "po_type              163\n"
     ]
    }
   ],
   "source": [
    "bigram_counter = Counter()\n",
    "for key in bigram.vocab.keys():\n",
    "    if len(key.split(\"_\")) > 1:\n",
    "        bigram_counter[key] += bigram.vocab[key]\n",
    "\n",
    "for key, counts in bigram_counter.most_common(20):\n",
    "    print '{0: <20} {1}'.format(key.encode(\"utf-8\"), counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "bigram_model = Word2Vec(bigram[df['tokenized_text']], size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words for apt1\n",
      "(u'2017', 0.9999014139175415)\n",
      "(u'campaigns', 0.9998936057090759)\n",
      "(u'vulnerabilities', 0.9998923540115356)\n",
      "(u'however', 0.9998865127563477)\n",
      "(u'says', 0.9998756647109985)\n",
      "(u'microsoft', 0.999866247177124)\n",
      "(u'behind', 0.9998636245727539)\n",
      "(u'recently', 0.999862551689148)\n",
      "(u'first', 0.9998561143875122)\n",
      "(u'actors', 0.9998513460159302)\n",
      "\n",
      "\n",
      "Most similar words for apt3\n",
      "(u'various', 0.9997950792312622)\n",
      "(u'hackers', 0.9997645616531372)\n",
      "(u'threat_actor', 0.9997585415840149)\n",
      "(u'infrastructure', 0.999748170375824)\n",
      "(u'fancy_bear', 0.9997477531433105)\n",
      "(u'cyber_espionage', 0.9997457265853882)\n",
      "(u'different', 0.9997384548187256)\n",
      "(u'operation', 0.9997243881225586)\n",
      "(u'found', 0.9997132420539856)\n",
      "(u'pawn_storm', 0.9997034072875977)\n",
      "\n",
      "\n",
      "Most similar words for apt10\n",
      "(u'number', 0.999851644039154)\n",
      "(u'code', 0.9998489618301392)\n",
      "(u'systems', 0.9998442530632019)\n",
      "(u'likely', 0.9998415112495422)\n",
      "(u'even', 0.9998409748077393)\n",
      "(u'kaspersky', 0.9998403787612915)\n",
      "(u'least', 0.9998272657394409)\n",
      "(u'2015', 0.9998213648796082)\n",
      "(u'time', 0.9998177289962769)\n",
      "(u'like', 0.9998167753219604)\n",
      "\n",
      "\n",
      "Most similar words for apt17\n",
      "(u'connection', 0.9996774196624756)\n",
      "(u'2014', 0.9996721744537354)\n",
      "(u'connections', 0.9996711015701294)\n",
      "(u'example', 0.999670684337616)\n",
      "(u'espionage', 0.9996696710586548)\n",
      "(u'find', 0.999664843082428)\n",
      "(u'made', 0.9996581077575684)\n",
      "(u'last', 0.9996574521064758)\n",
      "(u'accounts', 0.9996532201766968)\n",
      "(u'take', 0.999649703502655)\n",
      "\n",
      "\n",
      "Most similar words for apt28\n",
      "(u'spotted', 0.9996052980422974)\n",
      "(u'also', 0.9994975328445435)\n",
      "(u'one', 0.9994389414787292)\n",
      "(u'attackers', 0.9993807673454285)\n",
      "(u'sofacy', 0.99937504529953)\n",
      "(u'fireeye', 0.9993466138839722)\n",
      "(u'known', 0.999150276184082)\n",
      "(u'malware', 0.9991168975830078)\n",
      "(u'researchers', 0.9990829825401306)\n",
      "(u'targeted', 0.9990255832672119)\n",
      "\n",
      "\n",
      "Most similar words for apt29\n",
      "(u'analysis', 0.9998894333839417)\n",
      "(u'set', 0.9998882412910461)\n",
      "(u'emails', 0.9998800754547119)\n",
      "(u'multiple', 0.9998733997344971)\n",
      "(u'additional', 0.9998709559440613)\n",
      "(u'threat_group', 0.9998670220375061)\n",
      "(u'previously', 0.9998593330383301)\n",
      "(u'actors', 0.9998414516448975)\n",
      "(u'defense', 0.9998409748077393)\n",
      "(u'past', 0.9998399019241333)\n",
      "\n",
      "\n",
      "Most similar words for apt30\n",
      "(u'year', 0.9994930624961853)\n",
      "(u'evidence', 0.9994918704032898)\n",
      "(u'mandiant', 0.9994879364967346)\n",
      "(u'apt33', 0.9994726181030273)\n",
      "(u'lure', 0.9994692206382751)\n",
      "(u'team', 0.9994689226150513)\n",
      "(u'links', 0.9994667768478394)\n",
      "(u'possible', 0.9994623064994812)\n",
      "(u'trend_micro', 0.9994612336158752)\n",
      "(u'details', 0.9994591474533081)\n",
      "\n",
      "\n",
      "Most similar words for apt32\n",
      "(u'mandiant', 0.9999133944511414)\n",
      "(u'apt33', 0.9999080896377563)\n",
      "(u'last_year', 0.9999029040336609)\n",
      "(u'trend_micro', 0.9998987913131714)\n",
      "(u'military', 0.999896764755249)\n",
      "(u'active', 0.9998949766159058)\n",
      "(u'provided', 0.9998947978019714)\n",
      "(u'possible', 0.9998929500579834)\n",
      "(u'tracked', 0.99989253282547)\n",
      "(u'part', 0.9998922944068909)\n",
      "\n",
      "\n",
      "Most similar words for apt33\n",
      "(u'mandiant', 0.9999114274978638)\n",
      "(u'apt32', 0.9999080896377563)\n",
      "(u'possible', 0.9998906850814819)\n",
      "(u'active', 0.9998879432678223)\n",
      "(u'trend_micro', 0.9998870491981506)\n",
      "(u'military', 0.9998836517333984)\n",
      "(u'tracked', 0.999872088432312)\n",
      "(u'evidence', 0.9998656511306763)\n",
      "(u'latest', 0.9998624920845032)\n",
      "(u'last_year', 0.9998620748519897)\n",
      "\n",
      "\n",
      "Most similar words for apt34\n",
      "(u'revealed', 0.9996911287307739)\n",
      "(u'included', 0.9996631145477295)\n",
      "(u'fact', 0.9996280670166016)\n",
      "(u'apt33', 0.9996252655982971)\n",
      "(u'analysis', 0.9996103048324585)\n",
      "(u'latest', 0.9996023178100586)\n",
      "(u'apt32', 0.9995965957641602)\n",
      "(u'past', 0.9995937347412109)\n",
      "(u'actor', 0.9995870590209961)\n",
      "(u'june', 0.9995845556259155)\n",
      "\n",
      "\n",
      "Most similar words for apt37\n",
      "(u'response', 0.9997999668121338)\n",
      "(u'intelligence', 0.9997975826263428)\n",
      "(u'interests', 0.9997692704200745)\n",
      "(u'way', 0.9997625946998596)\n",
      "(u'iranian', 0.9997591972351074)\n",
      "(u'users', 0.9997578263282776)\n",
      "(u'service', 0.9997507929801941)\n",
      "(u'adobe', 0.999750018119812)\n",
      "(u'via', 0.9997493028640747)\n",
      "(u'ukraine', 0.9997483491897583)\n",
      "\n",
      "\n",
      "Most similar words for apt38\n",
      "(u'apt32', 0.999792754650116)\n",
      "(u'part', 0.9997857213020325)\n",
      "(u'based', 0.9997803568840027)\n",
      "(u'trend_micro', 0.9997755289077759)\n",
      "(u'tracked', 0.9997742176055908)\n",
      "(u'well', 0.9997742176055908)\n",
      "(u'many', 0.9997713565826416)\n",
      "(u'compromised', 0.999769926071167)\n",
      "(u'according', 0.9997689723968506)\n",
      "(u'actor', 0.9997662305831909)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/born-2-code/.local/lib/python2.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "for num in [1, 3, 5, 10, 12, 16, 17, 18, 19, 28, 29, 30, 32, 33, 34, 37, 38]:\n",
    "    term = \"apt%s\"%str(num)\n",
    "    if term in bigram_model.wv.vocab:\n",
    "        print(\"Most similar words for %s\"%term)\n",
    "        for t in bigram_model.most_similar(term): print(t)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After applying bigram phrases still we cannot see the desired results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
